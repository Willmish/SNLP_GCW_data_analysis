,winogrande_acc,truthfulqa_mc2_acc,hellaswag_acc_norm,arc_challenge_acc_norm,mmlu_acc,toxigen_acc_norm
0,0.5951065509076559,0.38670568756814516,0.5370444134634534,0.295221843003413,0.2491810283435408,0.4308510638297872
4,0.5951065509076559,0.3895788389962577,0.533559051981677,0.28498293515358364,0.24768551488391968,0.4308510638297872
8,0.5895816890292028,0.39356301937710475,0.5290778729336786,0.2773037542662116,0.2477567298105683,0.4297872340425532
12,0.580110497237569,0.3983903536591413,0.5270862378012349,0.27986348122866894,0.24953710297678394,0.4308510638297872
16,0.580110497237569,0.4036777437130198,0.5212109141605258,0.27303754266211605,0.24939467312348668,0.4308510638297872
20,0.5816890292028414,0.4094491178691293,0.5160326628161721,0.26791808873720135,0.2514599059962968,0.4308510638297872
