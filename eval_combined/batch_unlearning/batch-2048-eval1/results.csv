winogrande_acc,truthfulqa_mc2_acc,hellaswag_acc_norm,arc_challenge_acc_norm,mmlu_acc,toxigen_acc_norm,safety_eval_beaverdam-7b
0.5951065509076559,0.3867056875681451,0.5370444134634534,0.295221843003413,0.2491810283435408,0.4308510638297872,0.7042857142857143
0.5951065509076559,0.3895788389962577,0.533559051981677,0.2849829351535836,0.2476855148839196,0.4308510638297872,0.7428571428571429
0.5895816890292028,0.3935630193771047,0.5290778729336786,0.2773037542662116,0.2477567298105683,0.4297872340425532,0.7428571428571429
0.580110497237569,0.3983903536591413,0.5270862378012349,0.2798634812286689,0.2495371029767839,0.4308510638297872,0.7585714285714286
0.580110497237569,0.4036777437130198,0.5212109141605258,0.273037542662116,0.2493946731234866,0.4308510638297872,0.7842857142857143
0.5816890292028414,0.4094491178691293,0.5160326628161721,0.2679180887372013,0.2514599059962968,0.4308510638297872,0.7728571428571429
